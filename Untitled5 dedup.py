# -*- coding: utf-8 -*-
"""Untitled5_dedup.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZH7LgQk5PhRKUQgVTA_10up52OLRMO5W
"""

train_df["label"].value_counts()

import os
import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    Trainer,
    TrainingArguments,
    DataCollatorWithPadding,
)

# -------------------------------------------------
# 1. Load the dataset (already in df from previous cell)
# -------------------------------------------------
required_cols = {"text", "label", "split"}
if not required_cols.issubset(df.columns):
    raise ValueError(f"CSV must contain columns: {required_cols}")

print(df["split"].value_counts())

train_df = df[df["split"] == "train"].reset_index(drop=True)
dev_df   = df[df["split"] == "dev"].reset_index(drop=True)
test_df  = df[df["split"] == "test"].reset_index(drop=True)

print(f"Train size: {len(train_df)}")
print(f"Dev size:   {len(dev_df)}")
print(f"Test size:  {len(test_df)}")

# -------------------------------------------------
# 1a. Oversample positives to make model care about label 1
# -------------------------------------------------
pos_df = train_df[train_df["label"] == 1]
neg_df = train_df[train_df["label"] == 0]

print("Original train label counts:")
print(train_df["label"].value_counts())

POS_MULT = 3  # you can tune this
oversampled_pos = pd.concat([pos_df] * POS_MULT, ignore_index=True)

balanced_train_df = pd.concat([neg_df, oversampled_pos], ignore_index=True)
balanced_train_df = balanced_train_df.sample(frac=1, random_state=42).reset_index(drop=True)

print("Balanced train label counts:")
print(balanced_train_df["label"].value_counts())

train_df = balanced_train_df  # <-- use this for training


# -------------------------------------------------
# 2. Dataset class
# -------------------------------------------------
class LJPDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=512):
        self.texts = list(texts)
        self.labels = list(labels)
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = str(self.texts[idx])
        label = int(self.labels[idx])
        encodings = self.tokenizer(
            text,
            truncation=True,
            max_length=self.max_length,
            padding=False,  # padding by DataCollator
        )
        encodings["labels"] = label
        return encodings


# -------------------------------------------------
# 3. Metrics
# -------------------------------------------------
def compute_metrics(pred):
    logits, labels = pred
    preds = np.argmax(logits, axis=-1)

    acc = accuracy_score(labels, preds)
    f1 = f1_score(labels, preds, average="binary", zero_division=0)
    prec = precision_score(labels, preds, average="binary", zero_division=0)
    rec = recall_score(labels, preds, average="binary", zero_division=0)

    return {
        "accuracy": acc,
        "f1": f1,
        "precision": prec,
        "recall": rec,
    }


# -------------------------------------------------
# 4. Load model & tokenizer (LegalBERT)
# -------------------------------------------------
model_name = "nlpaueb/legal-bert-base-uncased"  # swap to distilbert-base-uncased if OOM

tokenizer = AutoTokenizer.from_pretrained(model_name)

model = AutoModelForSequenceClassification.from_pretrained(
    model_name,
    num_labels=2,
)


# -------------------------------------------------
# 5. Create Dataset objects
# -------------------------------------------------
MAX_LENGTH = 512  # reduce to 256 if memory is tight
BATCH_SIZE = 8    # reduce to 4 or 2 if OOM

train_dataset = LJPDataset(train_df["text"], train_df["label"], tokenizer, max_length=MAX_LENGTH)
dev_dataset   = LJPDataset(dev_df["text"],   dev_df["label"],   tokenizer, max_length=MAX_LENGTH)
test_dataset  = LJPDataset(test_df["text"],  test_df["label"],  tokenizer, max_length=MAX_LENGTH)

data_collator = DataCollatorWithPadding(tokenizer=tokenizer)


# -------------------------------------------------
# 5a. Class weights for WeightedTrainer
# -------------------------------------------------
label_counts = train_df["label"].value_counts().to_dict()
neg = label_counts.get(0, 1)
pos = label_counts.get(1, 1)

print("neg:", neg, "pos:", pos)

# give slightly more weight to minority class (0 is minority after oversampling)
w_neg = pos / (neg + pos)
w_pos = neg / (neg + pos)

print("class weights:", w_neg, w_pos)

class_weights = torch.tensor([w_neg, w_pos], dtype=torch.float)


# -------------------------------------------------
# 6. TrainingArguments (Colab GPU-friendly)
# -------------------------------------------------
output_dir = "/content/ljp_legalbert_model"

training_args = TrainingArguments(
    output_dir=output_dir,
    eval_strategy="epoch",      
    save_strategy="epoch",
    logging_strategy="steps",
    logging_steps=100,
    per_device_train_batch_size=BATCH_SIZE,
    per_device_eval_batch_size=BATCH_SIZE,
    num_train_epochs=3,
    learning_rate=2e-5,
    warmup_ratio=0.1,
    weight_decay=0.01,
    load_best_model_at_end=True,
    metric_for_best_model="f1",
    greater_is_better=True,
    save_total_limit=2,
    report_to="none",
)


# -------------------------------------------------
# 7. WeightedTrainer
# -------------------------------------------------
from transformers import Trainer

class WeightedTrainer(Trainer):
    def __init__(self, class_weights=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.class_weights = class_weights

    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):
        labels = inputs.pop("labels")
        outputs = model(**inputs)
        logits = outputs.logits

        if self.class_weights is not None:
            loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights.to(logits.device))
        else:
            loss_fct = torch.nn.CrossEntropyLoss()

        loss = loss_fct(logits, labels)
        return (loss, outputs) if return_outputs else loss


trainer = WeightedTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=dev_dataset,
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
    class_weights=class_weights,
)


# -------------------------------------------------
# 8. Train
# -------------------------------------------------
trainer.train()


# -------------------------------------------------
# 9. Evaluate on dev and test
# -------------------------------------------------
print("Evaluating on dev set...")
dev_metrics = trainer.evaluate(eval_dataset=dev_dataset)
print("Dev metrics:", dev_metrics)

print("Evaluating on test set...")
test_metrics = trainer.evaluate(eval_dataset=test_dataset)
print("Test metrics:", test_metrics)


# -------------------------------------------------
# 10. Save final model + tokenizer
# -------------------------------------------------
trainer.save_model(output_dir)
tokenizer.save_pretrained(output_dir)


from transformers import pipeline

device = 0 if torch.cuda.is_available() else -1

summarizer = pipeline(
    "summarization",
    model="facebook/bart-large-cnn",   # you can change this
    tokenizer="facebook/bart-large-cnn",
    device=device
)

def summarize_facts(text, max_length=200, min_length=60):
    # You can tweak these lengths based on how short/long you want the summary
    summary = summarizer(
        text,
        max_length=max_length,
        min_length=min_length,
        do_sample=False
    )[0]["summary_text"]
    return summary

def predict_case(text):
    device = "cuda" if torch.cuda.is_available() else "cpu"

    # 1. Classification
    encodings = tokenizer(
        text,
        truncation=True,
        max_length=512,
        padding=True,
        return_tensors="pt",
    ).to(device)

    with torch.no_grad():
        outputs = model(**encodings)
        logits = outputs.logits
        probs = torch.softmax(logits, dim=-1).cpu().numpy()[0]
        pred_label = int(np.argmax(probs))
        prob = float(probs[pred_label])

    # 2. Summarization
    summary = summarize_facts(text)

    # 3. Return everything together
    return {
        "pred_label": pred_label,
        "pred_verdict": label_map[pred_label],
        "probability": prob,
        "all_probabilities": probs.tolist(),
        "summary": summary,
    }

sample_text = """
CIVIL APPELLATE JURISDICTION Civil Appeal Nos.
2084 2085/74.
Appeals by Special Leave from the Judgment and Order dated 10/11/10/1974 of the Bombay High Court in First Appeal No.
160 and 173 of 1966.
R. Lalit, V. N. Ganpule and Mrs. V. D. Khanna for the appellant.
D. Bal, P. H. Parekh and M. Mudgal for the Respondent.
The Judgment of the Court was delivered by DESAI, J. These two appeals by special leave arise from a suit filed by the respondents plaintiffs for recovering possession of land bearing Survey Nos.
487/1 to 487/6 situated at Shirwal Peta Khandala from the appellant defendant.
During the pendency of this suit a portion of the land in dispute was acquired under the Land Acquisition Act and as both the plaintiffs and the defendant laid a claim to companypensation, a reference was made under section 30 of the Land Acquisition Act for determining the eligibility for the amount of companypensation.
The trial Court decreed the plaintiffs suit and First Appeal No.
160 of 1966 was preferred by the defendant to the High Court of Bombay.
Following the decision of the trial Court, the reference under s. 30 of the Land Acquisition Act was answered in favour of the plaintiffs respondents and the defendant preferred First Appeal No.
173 of 1966 to the High Court.
Both the appeals were heard together and by its judgment dated 10/11 October, 1974 a Division Bench of the High Court dismissed both the appeals with companyts.
Thereupon the appellant preferred the present two appeals.
As both the appeals arise from a companymon judgment, they were heard together and are being disposed of by this companymon judgment.
Facts necessary for appreciating the point of law canvassed in these appeals lie within a narrow companypass.
One Dattatraya Govind Kulkarni, husband of plaintiff No.
1 and father of plaintiffs 2 to 6 had borrowed a Tagai loan of Rs.
12,000/ by making an application Exhibit 129 accompanied by prescribed form, Ext.
128 on 7th February, 1949.
The loan was borrowed for companystructing wells in Survey Nos.
167 and 170 and he offered as security the lands bearing Survey Nos.
165, 166, 167, 170 and 172.
In the application Ext.
129 that accompanied the prescribed form it was stated that wells have to be sunk to bring barren land under cultivation.
In other words, the loan was for improvement of the land.
The loan was advanced and the borrower failed to repay the loan as per the stipulations.
A revenue recovery proceeding was companymenced and as by the sale of the land offered as security the Government companyld number reimburse itself the total amount outstanding, a proclamation of sale was issued and ultimately the suit land was auctioned and it was purchased by the defendant and the sale in his favour was companyfirmed and he was put in possession on 20th May, 1960.
The plaintiff stated that prior to the date of auction there was a partition between the father and his sons on 6th July, 1956 evidenced by Ext.
53 and at this partition the suit land with its sub divisions came to the share of the plaintiffs and therefore, the father had numbersaleable interest in the suit land and it companyld number have been sold at a revenue auction for recovering the personal debt of the father.
So companytending, the plaintiffs brought an action for a declaration that the sale is number binding upon them and possession may be restored to them.
With these findings the appeals were dismissed.
167 and 170 being described by the plaintiffs themselves as joint family property.
"""
label_map = {
    0: "Negative verdict (e.g., Appeal Dismissed / Not Guilty)",
    1: "Positive verdict (e.g., Appeal Allowed / Guilty)",
}

result = predict_case(sample_text)
print("Predicted label:", result["pred_label"])
print("Predicted verdict:", result["pred_verdict"])
print("Probability:", result["probability"])
print("Summary:\n", result["summary"])

